{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import perf_counter\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import mode\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The K-Nearest Neighbors (KNN) algorithm is a simple, versatile machine learning algorithm used for both classification and regression tasks. Here's a high-level explanation of how it works, along with algorithmic steps:\n",
    "\n",
    "1. Data preparation:\n",
    "   - Have a dataset with labeled examples\n",
    "   - Choose a value for K (the number of nearest neighbors to consider)\n",
    "\n",
    "2. For a new data point to be classified or have its value predicted:\n",
    "\n",
    "   a. Calculate the distance between the new point and all points in the dataset\n",
    "      - Common distance metrics: Euclidean distance, Manhattan distance, or Hamming distance\n",
    "\n",
    "   b. Sort the distances in ascending order\n",
    "\n",
    "   c. Select the K points with the smallest distances to the new point\n",
    "\n",
    "   d. For classification:\n",
    "      - Count the frequency of each class among the K neighbors\n",
    "      - Assign the most frequent class to the new point\n",
    "\n",
    "      For regression:\n",
    "      - Calculate the average (or weighted average) of the target values of the K neighbors\n",
    "      - Assign this average as the predicted value for the new point\n",
    "\n",
    "3. Return the predicted class or value for the new data point\n",
    "\n",
    "Key considerations:\n",
    "- Choice of K: Smaller K can lead to overfitting, larger K to smoother decision boundaries\n",
    "- Distance metric: Choose based on the nature of your data\n",
    "- Scaling: Normalize or standardize features if they're on different scales\n",
    "- Dimensionality: KNN can struggle with high-dimensional data (curse of dimensionality)\n",
    "\n",
    "This algorithm is intuitive and doesn't require a separate training phase, but it can be computationally expensive for large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 1000\n",
    "num_features = 1000\n",
    "num_informative = min(num_features, 100)\n",
    "X, y = make_classification(\n",
    "    n_samples=num_samples,\n",
    "    n_classes=4,\n",
    "    n_features=num_features,\n",
    "    n_informative=num_informative,\n",
    "    n_redundant=num_features-num_informative,\n",
    "    n_repeated=0,\n",
    "    n_clusters_per_class=1,\n",
    "    weights=[0.7, 0.12, 0.15, 0.03],\n",
    "    random_state=2024,\n",
    "    hypercube=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of nearest neighbors\n",
    "K = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 1: Brute force $O(n^2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.8772 seconds\n"
     ]
    }
   ],
   "source": [
    "start = perf_counter()\n",
    "norms_v1 = np.zeros((num_samples, num_samples), dtype=np.float32)\n",
    "for i in range(num_samples):\n",
    "    # calculate distances only for upper triangular matrix\n",
    "    for j in range(i, num_samples):\n",
    "        diff = X[i] - X[j]\n",
    "        norms_v1[i, j] = np.linalg.norm(diff)\n",
    "\n",
    "# calculate pairwise distances\n",
    "pairwise_distances_v1 = norms_v1 + norms_v1.T\n",
    "\n",
    "# get the indices that sort the pairwise distances\n",
    "sorted_distances_indices_v1 = np.argsort(pairwise_distances_v1, axis=1)\n",
    "print(f'Time taken: {(perf_counter() - start):.4f} seconds')\n",
    "# norms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 2: No `for` loops (NumPy vectorization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 32.0112 seconds\n"
     ]
    }
   ],
   "source": [
    "start = perf_counter()\n",
    "# change the shapes to allow for broadcasting\n",
    "diff = X[:, None, :] - X[None]\n",
    "\n",
    "# pairwise distances\n",
    "pairwise_distances_v2 = np.linalg.norm(diff, axis=-1, keepdims=True).squeeze()\n",
    "\n",
    "# indices that sort the distances\n",
    "sorted_distances_indices_v2 = np.argsort(pairwise_distances_v2, axis=1)\n",
    "print(f'Time taken: {(perf_counter() - start):.4f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 74.00%\n"
     ]
    }
   ],
   "source": [
    "# randomly select some points\n",
    "samples = np.random.choice(len(X), size=50, replace=False)\n",
    "\n",
    "# find the sorted distances of the neighbors of the sampled points\n",
    "neighbor_distances_indices = sorted_distances_indices_v2[samples][:, : K + 1]\n",
    "\n",
    "# get the class information of all the neighbors\n",
    "# first column is the sample itself since its pairwise distance with itself is obviously zero\n",
    "neighbor_classes = y[neighbor_distances_indices[:, 1:]]\n",
    "\n",
    "# get the most frequent class as the predictions\n",
    "predictions = mode(neighbor_classes, axis=1)[0]\n",
    "\n",
    "# ground truth of the samples\n",
    "true_class = y[neighbor_distances_indices[:, 0]]\n",
    "\n",
    "# calculate accuracy\n",
    "accuracy = (sum(predictions == true_class) / len(true_class)).item()\n",
    "print(f\"Accuracy: {(accuracy * 100):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.84        35\n",
      "           1       0.00      0.00      0.00         4\n",
      "           2       1.00      0.25      0.40         8\n",
      "           3       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.74        50\n",
      "   macro avg       0.43      0.31      0.31        50\n",
      "weighted avg       0.67      0.74      0.65        50\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lakshya/micromamba/envs/ml/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/lakshya/micromamba/envs/ml/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/lakshya/micromamba/envs/ml/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true=true_class, y_pred=predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
